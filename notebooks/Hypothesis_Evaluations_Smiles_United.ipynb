{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realiability and Significance testing\n",
    "This notebook utilizes the cleaned and saved dataframes to evaluate the reliability of survey questions and assess the significance of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pingouins (optional)\n",
    "Un hash the below if you need to install or upgrade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pingouin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9', \"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_df = pd.read_pickle(\"../saved_data_frames/hypothesis_df.pkl\")\n",
    "#hypo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly extract 50 data points for Reliability testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_50 = hypo_df.sample(n=50, random_state=186)\n",
    "#reliability_50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert answers to numerical scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {\n",
    "    \n",
    "    # true/false (knowledge)\n",
    "    'True':1,\n",
    "    'False':2,\n",
    "    \n",
    "    # frequency (knowledge)\n",
    "    'Less than 1 time each month':1,\n",
    "    '1 time each month': 2,\n",
    "    '1 time each week':3,\n",
    "    '2 to 3 times each week':4,\n",
    "    '1 time each day':5,\n",
    "    '2 to 3 times each day':6,\n",
    "    \n",
    "    # percent ranges\n",
    "    'None of the residents under my care experience bleeding when brushing their teeth':1,\n",
    "    'Less than 25%':2,\n",
    "    '25% to 50%':3,\n",
    "    '50% to 75%':4,\n",
    "    'Greater than 75%':5, \n",
    "    \n",
    "    # agree - disagree (attitude)\n",
    "    'Strongly Agree':1,\n",
    "    'Agree':2,\n",
    "    'Neutral':3,\n",
    "    'Disagree':4,\n",
    "    'Strongly Disagree':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_answers = reliability_50.replace(convert_dict)\n",
    "num_answers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability Coefficient using Cronbach's Alpha\n",
    "Cronbach's alpha coefficient, often referred to as simply \"Cronbach's alpha,\" is a widely used measure of reliability in the context of Likert scale data and surveys. It assesses the internal consistency of a set of Likert-type items, indicating the degree to which those items are measuring the same underlying construct or dimension.\n",
    "\n",
    "Here are some key points about using Cronbach's alpha coefficient to assess reliability with Likert data:\n",
    "\n",
    "1. **Internal Consistency:** Cronbach's alpha assesses the degree to which items in a Likert scale or questionnaire consistently measure the same concept or construct. In other words, it measures how closely related the responses to different items are within the same scale.\n",
    "\n",
    "2. **Scale Structure:** It's typically used for scales or questionnaires where respondents rate their agreement or disagreement with a series of statements on a scale (e.g., strongly agree, agree, neutral, disagree, strongly disagree).\n",
    "\n",
    "3. **Range of Values:** Cronbach's alpha ranges from 0 to 1, with higher values indicating greater internal consistency. Generally, an alpha of 0.70 or higher is considered acceptable for most research purposes, although the specific threshold may vary depending on the field and context.\n",
    "\n",
    "4. **Calculation:** The formula for Cronbach's alpha involves calculating the average correlation between each item and all other items in the scale. A higher alpha suggests that the items are more closely related.\n",
    "\n",
    "5. **Interpreting Results:** If Cronbach's alpha is too low, it may indicate that the items in the scale are not measuring the same underlying construct effectively, and some items may need to be revised or removed. On the other hand, a very high alpha might suggest redundancy among items.\n",
    "\n",
    "6. **Contextual Considerations:** While Cronbach's alpha is a valuable tool, it's important to consider the context of your study and the specific construct you are measuring. In some cases, lower alpha values may be acceptable if the scale is meant to capture a diverse range of opinions.\n",
    "\n",
    "7. **Sample Size:** Sample size can influence the stability of Cronbach's alpha estimates. Larger samples tend to produce more reliable estimates of alpha.\n",
    "\n",
    "In summary, Cronbach's alpha helps ensure that the items within a scale or questionnaire are consistent in measuring the intended construct, increasing the confidence in the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract out just Likert Scale Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in enumerate(num_answers.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likert = num_answers[num_answers.columns[6:12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cronbach's Alpha of Likert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.cronbach_alpha(data=likert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guttman's Lambda\n",
    "Guttman's Lambda is a measure of internal consistency and reliability used for ordinal data. It is an alternative to Cronbach's alpha, specifically designed for assessing the internal consistency of ordinal variables. Guttman's Lambda evaluates how well a set of items or questions within a scale measures a single underlying construct or dimension.\n",
    "\n",
    "Here are some key points about Guttman's Lambda:\n",
    "\n",
    "1. **Purpose:** Guttman's Lambda is used to assess the internal consistency of a set of items or questions with ordered response categories. It helps determine the extent to which these items are measuring the same underlying construct or trait.\n",
    "\n",
    "2. **Ordinal Data:** Guttman's Lambda is particularly well-suited for ordinal data, where the response categories have a meaningful order but may not have equal intervals between them. It can be applied to Likert scale items, Likert-type questions, and other ordinal variables.\n",
    "\n",
    "4. **Range:** Guttman's Lambda values range from 0 to 1, similar to Cronbach's alpha. Higher values indicate greater internal consistency among the items, suggesting that the items are measuring the same underlying construct more reliably.\n",
    "\n",
    "5. **Interpretation:** When interpreting Guttman's Lambda, a value close to 1 suggests high internal consistency among the items, indicating that they effectively measure the intended construct. Conversely, a lower value may indicate inconsistency or a need to revise the items within the scale.\n",
    "\n",
    "7. **Advantages:** Guttman's Lambda takes into account the ordered relationships between response categories, making it a suitable choice for assessing reliability when dealing with ordinal data. It provides a more accurate measure of internal consistency for such data compared to Cronbach's alpha.\n",
    "\n",
    "In summary, Guttman's Lambda is a valuable tool for assessing the internal consistency and reliability of ordinal data, particularly when dealing with items or questions that have ordered response categories. Use it to ensure that the items within a scale are effectively measuring the same underlying construct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract out just Ordinal Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = num_answers[num_answers.columns[12:15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat_percent = np.cov(percentages, rowvar=False)\n",
    "cov_mat_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the reduced covariance matrices by excluding diagonal elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_percent = cov_mat_percent - np.diag(np.diag(cov_mat_percent))\n",
    "reduced_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Guttman's Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determinant of FULL covariance matrix of percentages\n",
    "deter_full_percent = np.linalg.det(cov_mat_percent)\n",
    "\n",
    "# determinant of REDUCED covariance matrix of percentages\n",
    "deter_reduced_percent = np.linalg.det(reduced_percent)\n",
    "\n",
    "guttmans_lambda_percent = deter_reduced_percent / deter_full_percent\n",
    "print(f\"Guttman's Lambda of Percentage questions: {guttmans_lambda_percent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuder-Richardson Formula (KR-20) \n",
    "The Kuder-Richardson Formula 20 (KR-20) is a reliability coefficient used to assess the internal consistency of a test or set of items with dichotomous (binary) responses, such as correct and incorrect answers. KR-20 is a variant of the Kuder-Richardson reliability formula, and it is commonly used in educational and psychological research to measure the consistency of test items that have only two possible responses.\n",
    "\n",
    "Here are some key points about KR-20:\n",
    "\n",
    "1. **Purpose:** KR-20 is used to determine how well a set of dichotomous test items (questions or items with only two response options, often correct and incorrect) measures a single underlying construct or trait. It evaluates whether these items consistently assess the same characteristic.\n",
    "\n",
    "2. **Binary Data:** KR-20 is specifically designed for data with two response categories, typically coded as 1 (correct) and 0 (incorrect). It assumes that items are scored in a binary fashion.\n",
    "\n",
    "3. **Calculation:** The formula for KR-20 involves calculating the proportion of variance explained by the differences in the respondents' scores on the test items. It takes into account the number of items, the mean score, and the variance of scores.\n",
    "\n",
    "4. **Interpretation:** KR-20 values range from 0 to 1. Higher values indicate greater internal consistency among the test items, suggesting that the items are measuring the same underlying construct more reliably. A KR-20 value close to 1 suggests high internal consistency, while a lower value indicates lower consistency.\n",
    "\n",
    "5. **Limitations:** KR-20 has limitations. It assumes that the test items are parallel forms of each other, meaning that they have the same level of difficulty and measure the same construct. It may not be appropriate for tests with items that have different levels of difficulty or items that measure multiple dimensions.\n",
    "\n",
    "6. **Usage:** KR-20 is commonly used in educational assessments, particularly for multiple-choice exams where each question has only two possible answers (correct or incorrect).\n",
    "\n",
    "Here's the formula for calculating KR-20:\n",
    "\n",
    "$$KR20 = \\frac{k}{k-1}\\displaystyle \\Bigg (1 - \\frac{\\sum \\limits _{j=1} ^{k} p_{j} q_{j}}{\\sigma^2}\\Bigg ) $$\n",
    "where:\n",
    "\n",
    "- $k$: Total number of questions\n",
    "- $p_{j}$: Proportion of individuals who answered question j correctly\n",
    "- $q_{j}$: Proportion of individuals who answered question j incorrectly \n",
    "- $\\sigma^2$: Variance of scores for all individuals who took the test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kuder_richardson(df):\n",
    "\n",
    "    # Total number of questions\n",
    "    k = len(df.columns)\n",
    "    \n",
    "    # Proportion of individuals who answered question j correctly\n",
    "    pj = df.mean()\n",
    "    \n",
    "    # Proportion of individuals who answered question j incorrectly\n",
    "    qj = 1-pj\n",
    "    \n",
    "    # Variance of scores for all individuals who took the test\n",
    "    o2 = np.var(df.sum(axis=1), ddof=1)\n",
    "    \n",
    "    # Calculate KR-20 coefficient\n",
    "    KR_20 = (k / (k - 1)) * (1 - ((np.sum(pj*qj) / o2)))\n",
    "\n",
    "    #print(\"KR-20 Coefficient:\", KR_20)\n",
    "    \n",
    "    return KR_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dicatomous questions \n",
    "t_f = num_answers[num_answers.columns[2:6]]\n",
    "frequency = num_answers[num_answers.columns[-2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to correct/incorrect\n",
    "[i for i in enumerate(t_f.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_col0 = [1 if answer == 1 else 0 for answer in t_f[t_f.columns[0]]] # fluoridated products\n",
    "\n",
    "binary_col1 = [1 if answer == 2 else 0 for answer in t_f[t_f.columns[1]]] # healthy gums bleed\n",
    "\n",
    "binary_col2 = [1 if answer == 1 else 0 for answer in t_f[t_f.columns[2]]] # Dry mouth\n",
    "\n",
    "binary_col3 = [1 if answer == 1 else 0 for answer in t_f[t_f.columns[3]]] # Snacking bad\n",
    "\n",
    "t_f[t_f.columns[0]] = binary_col0\n",
    "t_f[t_f.columns[1]] = binary_col1\n",
    "t_f[t_f.columns[2]] = binary_col2\n",
    "t_f[t_f.columns[3]] = binary_col3\n",
    "\n",
    "kr_20_tf = kuder_richardson(t_f)\n",
    "\n",
    "print(\"KR-20 Coefficient:\", kr_20_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in enumerate(frequency.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_c0 = [1 if answer == 6 \\\n",
    "               else 0 for answer in frequency[frequency.columns[0]]] # How often should residents brush\n",
    "\n",
    "binary_c1 = [1 if answer == 6 \\\n",
    "               else 0 for answer in frequency[frequency.columns[1]]] # How often should residents floss\n",
    "\n",
    "frequency[frequency.columns[0]] = binary_c0\n",
    "frequency[frequency.columns[1]] = binary_c1  \n",
    "\n",
    "kr_20_freq = kuder_richardson(frequency)\n",
    "\n",
    "print(\"KR-20 Coefficient:\", kr_20_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = pd.concat([t_f, frequency], axis=1)\n",
    "kr_20_binary = kuder_richardson(binary)\n",
    "\n",
    "print(\"KR-20 Coefficient:\", kr_20_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    " \n",
    "def combos(arr, r):\n",
    " \n",
    "    # return set of all subsets of length r\n",
    "    return set(list(combinations(arr, r)))\n",
    "\n",
    "\n",
    "tup_list = []\n",
    "for length_of_tuples in range(2,len(binary.columns)):\n",
    "    tup_list.extend(list(combos(list(range(len(binary.columns))), length_of_tuples)))\n",
    "\n",
    "                    \n",
    "#tup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "best_cols = []\n",
    "for tup in tup_list:   \n",
    "    df_cols = []\n",
    "    temp_dfs = []\n",
    "    df = binary[binary.columns[list(tup)]]\n",
    "    df_cols.append(list(df.columns))\n",
    "    kr_coeff = kuder_richardson(df)\n",
    "    if kr_coeff > best:\n",
    "        best = kr_coeff\n",
    "        best_cols = list(df.columns)\n",
    "        \n",
    "print(best)\n",
    "print(best_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove `reliability_50` from `hypo_df` to create `sig_testing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_testing = hypo_df.drop(index=list(reliability_50.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `None` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_testing = sig_testing.replace(\n",
    "    {'None of the residents under my care experience bleeding when brushing their teeth':\n",
    "     'None'}\n",
    ")\n",
    "sig_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(sig_testing, \"../saved_data_frames/sig_testing_PRE.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import mannwhitneyu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
